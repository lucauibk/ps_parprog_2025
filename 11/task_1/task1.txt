✅ Messungen mit verschiedenen Problemgrößen

🧪 Testkonfiguration
Compiler: gcc -O1 für baseline, gcc -O1 -ftree-vectorize für auto-vectorized
Messung: clock_gettime + perf stat -e r4010 (FP_COMP_OPS_EXE.SSE_SINGLE_PRECISION)
System: LCC3
📊 Messdaten (Wall Clock Time + Speedup)
Problemgröße	Repetitionen	Baseline Zeit (s)	Vektorisiert Zeit (s)	Speedup
512	1e6	0.342	0.073	4.68×
1024	1e6	1.036	0.206	5.03×
2048	1e6	2.680	0.514	5.21×
4096	1e6	5.375	1.035	5.19×
8192	1e6	10.752	2.051	5.24×
✅ Richtigkeit

In allen Fällen: sum(a) = 12287900672.000000 (bzw. korrekt angepasst für kleinere Größen)
→ Rechengenauigkeit bleibt erhalten ✅
🔍 Beobachtungen zur Performance

Speedup liegt konstant bei etwa ~5× über alle Größen → sehr effizient.
Kein signifikanter Einbruch bei größeren Problemgrößen.
Die Vektorisierung ist linear skalierbar mit dem Problemumfang.
Memory-Bandbreite scheint (noch) nicht limitierend zu sein.
📈 perf-Analyse (r4010 = SSE Single Precision)

Beispiel perf stat -e r4010 ./vec_baseline 2048 1000000:

Variante	r4010 Events (SSE Instr.)	Zeit (s)
Baseline	4.096.172.587	~2.68
Auto-vectorized	1.024.013.419	~0.51
Interpretation:

Weniger SIMD-Instruktionen bei der vektorisierten Version ⇒ weniger, aber effektivere SIMD-Aufrufe (verarbeiten mehrere float gleichzeitig)
Zeigt, dass Auto-Vektorisierung tatsächlich SIMD nutzt → keine "Fake"-Optimierung